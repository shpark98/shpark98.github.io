---
published: true

layout: single

title: "[2023-07-14] 1. Epipolar Geometry"

categories: [Devcourse-TIL]

tags: Autonomous_Driving SLAM

toc: true

toc_label : 목차

toc_sticky: true

author_profile: false

sidebar :
    nav : "docs"
---

## Epipolar Geometry



### Why 2-view Geometry?

- 3D -> 2D Mapping - Success! 

- 2D -> 3D Mapping - ?????????

  

- 우리가 Intrinsic과 Extrinsic을 알고 있으면 Matrix의 Inverse를 곱해서 2D에서 3D를 알 수 있음

  - 하지만 실제 세상에서 우리는 Extrinsic을 알지 못하는 경우가 많음
  - Extrinsic을 알고 있다는 자체가 이미 3D Point의 위치를 알고 있다는 것을 의미함
    - VSLAM, Mapping의 목적은 이 3D Point의 x의 위치(Extrinsic)을 구하는 것

- Intrinsic을 알고 있어도 Extrinsic을 알고 있지 못해 Depth의 값을 재생성 할 수 없음

  - 하지만 Depth의 값을 알고 있는 RGB-D 카메라의 경우에는 3D 포인트의 위치를 이미지 하나로 알 수 있음

  - 그러면 SLAM을 안해도 되는 것 아닌가?
    - 하지만 RGB-D 카메라로부터 얻는 Depth값은 크게 요동치는 경우가 많음
    - 센서 노이즈가 상당히 큼 -> 이 정보를 보정하기 위해 여러 장의 이미지를 사용하여 VSLAM을 수행 후 정확한 Mapping 정보를 받을 수 있음

- 또한 VSLAM은 Mapping외에 Localization이라는 목적도 있음

  - 이동하면서 위치를 알아내는 목적

- 3D 맵을 점차 확장 시켜나가기 위해 RGB-D 카메라로 다 끝난 것이 아닌 여러장의 이미지가 필요하게 됨

- 3D -> 2D Mapping은 1장의 이미지로 가능하지만, 2D -> 3D Mapping은 1장으로는 불가능함

  - 2D -> 3D Mapping은 적어도 새로운 차원의 정보를 줄 수 있는 데이터가 필요함(최소 2장의 view)

  

- VSLAM을 하기 위해서 우리는 매 이미지 프레임마다 카메라가 얼마나 이동했는지 구해야 함

- 이미지간의 카메라 Frame의 Rigid Body Motion(Pose 이동)을 구해야 함
  - 모션 정보는 Proprioceptive Sensor을 통해 모션 값을 받으면 바로 알 수 있음
  - 하지만, VSLAM의 경우에서는 이런 Proprioceptive Sensor 없이 Visual 정보만(영상)으로 모션 값을 추론할 수 있어야 함
    - 2개 이미지간의 기하학적 상관관계를 통해 모션을 추출 할 수 있음




### Epipolar Geometry



#### Epipolar Geometry

- 2-view Geometry

- 아래의 그림은
  - Monocular 카메라의 경우 : Image plane 1은 과거에 이미지를 받고, Image plane 2는 현재에 이미지를 받은 것으로 볼 수 있음
  - Stereo 카메라의 경우 : Image plane 1, 2를 동시간의 왼쪽 카메라, 오른쪽 카메라의 이미지를 받은 것으로 볼 수 있음
- 2-view Geometry는 Monocular, Stereo 둘 다 적용이 가능함
- 이런 2-view Geometry는 **Epipolar Geometry** 라고 함

<img src="https://github.com/shpark98/Projects/assets/116723552/0577b470-cc4e-48d9-9887-f6ffe3c39707" alt="image" style="zoom:67%;" />

#### Epipolar line

- ray를 투영하는 직선
- 왼쪽 카메라와 오른쪽 카메라가 함께 바라보는 3D Point가 있다고 하자
  - 왼쪽 카메라의 시점에서 점 x는 3D에서 ray 위의 어딘가이 있는 Point임
  - 오른쪽 카메라에서 함께 보고 있다고 한다면, ray는 epipolar line 위에 투영이 됨

- 오른쪽 카메라 입장에서 봤을 때는 왼쪽 카메라와 오른쪽 카메라가 함께 보는 어떤 3D Point가 있을 때, 오른쪽 카메라 이미지속 어떤 픽셀에 상이 맺힐까 라는 문제를 epipolar line을 통해 풀 수 있음

- 두 카메라(optical center 1, 2)의 Rigid Body Motion(optical center 1, 2의 rotation과 translation)을 구하기 위해서는 무조건 epipolar line 위에 있을 수 밖에 없다는 전제 조건은 굉장히 유용함

<img src="https://github.com/shpark98/Projects/assets/116723552/0577b470-cc4e-48d9-9887-f6ffe3c39707" alt="image" style="zoom:67%;" />



#### Epipole

- 왼쪽 카메라가 3개의 point를 보고 있다고 가정하면 x1, x2, x3에 대한 상이 맺히게 됨
- 각각의 상들마다 ray가 만들어지므로 ray1, ray2, ray3가 생성됨
- ray1, ray2, ray3를 오른쪽 카메라 이미지에 재투영을 시키면 l1, l2, l3라는 epipolar line이 생성됨
- 종종 l1, l2, l3가 한 점에서 교차할 때가 있는데 이 점을 **Epipole**이라고 함
  - 교차하는 점이 의미하는 것이 무엇일까?
    - Epipolar line들이 교차하는 곳은, ray들이 교차하는 곳과 동일하므로 Optical center이 투영된 것으로 볼 수 있음
    - epipole e1은 Optical center2가 투영된 것이고, epipole e2는 Optical center1이 투영된 것

<img src="https://github.com/shpark98/Projects/assets/116723552/11200719-abfe-49d7-8ff2-18d32cffd8ad" alt="image" style="zoom:67%;" />



##### Special Cases of Epipole Placements

- case #1
  - Stereo Camera with no rotation and only lateral translation
  - 아래의 그림과 같은 상황일 때는?
  - Epipole이 나타나지 않음
    - 왼쪽의 시점을 오른쪽 카메라가 볼 수 없고 오른쪽 시점을 왼쪽 카메라가 볼 수 없기 때문
    - Epipolar line 자체가 완전히 평행하게 나타나서 Epipole 자체가 생성되지 않음
  - Epipolar line이 가로이므로 correspondence를 찾기 굉장히 쉬움 (stereo matching도 쉽게 수정 가능)

<img src="https://github.com/shpark98/Projects/assets/116723552/f9ceef1a-b9d4-4a25-9f56-07a4f664f1a0" alt="image" style="zoom:67%;" />



- case #2

  - Monocular Camera forward motion with no rotation and Forward movement
  - 아래의 그림과 같은 상황일 때는?
    - Epipole e1과 e2가 직선에 놓임

  - Epipole의 위치를 분석하여 correspondence 없이도 relative motion을 구할 수 있음
    - 회전값이 없다는 점을 이용

<img src="https://github.com/shpark98/Projects/assets/116723552/89b431e2-cdab-4057-94c9-653dc2a3c809" alt="image" style="zoom:67%;" />

#### Epipolar Plane

- 좌측 이미지와 우측 이미지의 optical center을 연결하고 왼쪽 이미지의 Ray와 오른쪽 이미지의 Ray를 연결하여 삼각형(Epipolar Plane, 파이) 생성

<img src="https://github.com/shpark98/Projects/assets/116723552/9aaca929-6c8f-4b83-8b87-dca5e92198aa" alt="image" style="zoom:67%;" />



#### Baseline

- 좌측, 우측 이미지의 optical center을 연결할 때 생기는 직선
- 2 카메라간의 거리 값
- Stereo 카메라를 사용할 때 Baseline 크기가 크면 클 수록 삼각측량의 정확도가 높아짐 
- baseline이 image plane을 통과하게 되면 그 통과하는 점이 epipole이 됨
  - epipole들은 baseline 직선 위에 있음
- Epipolar Plane은 baseline을 갖고 있으며 Optical center에서 baseline과 ray가 교차함



- 하나의 이미지에서 여러개의 3D Point을 측량하는 것이 가능함
- 다양한 3D Point가 위치가 있다고 할 수 있음
- 3D Point x의 위치를 조금 변경하고 각각의 case 마다 Epipolar Plane을 보면 baseline을 중점으로 회전함

<img src="https://github.com/shpark98/Projects/assets/116723552/8ab05929-11b0-4c52-b941-8ace7ad58b1b" alt="image" style="zoom:67%;" />



#### Correspondence가 있기 위한 3가지 조건(Epipolar Constriant)

1. 3D Point x는 Epipolar Plane 위에 있어야 함

2. 모든 Epipolar line들은 Epipole과 교차해야 함
3. 모든 Baseline들은 Epipole과 교차해야 하며, 모든 Epipolar Plane은 Baseline을 포함하고 있어야 함





### Essential / Fundamental matrix



#### Essential matrix

- Epipolar Constriant에 대한 정보(삼각형 모양 안의 두 카메라간의 회전과 이동)를 담고 있는 3 x 3 matrix
- 카메라 모션을 추정하기 위해 correspondence를 정확하게 아는 것이 중요한데, 이 correspondence 정확하게 얻어 낼 수 있게 해주는 것이  Epipolar Constriant임
  - 따라서 카메라 모션을 정확하게 추론하기 위해서는 Essential matrix를 얻어내는 과정이 중요함

<img src="https://github.com/shpark98/Projects/assets/116723552/e30b4928-3142-474e-92f6-d6a2ea2629b3" alt="image" style="zoom:67%;" />



- 왼쪽 이미지에 맺힌 상 하나와 오른쪽 이미지에 맺힌 상 하나를 Essential Matrix가 엮어주면서 기하학적인 Constriant를 만듬

- Essential Matrix는 translation과 Rotation의 Cross Product로 이루어짐
  - t는 3 x 1 벡터 이지만 Cross Product를 하기 위해 skew symmetric matrix로 바꿔서 3 x 3 Matrix가 됨
  - 거기에 3 x 3 Matrix인 SO(3) Rotation Matrix 를 곱해줌으로써 3 x 3 Essential Matrix가 됨

![image](https://github.com/shpark98/Projects/assets/116723552/f5c790b2-9b0d-405c-81ff-dd606465ea94)



- x가 어떻게 표현되는지 모름

  - x의 위치는 Normalized 이미지 Plane을 사용하여 소수점으로 표현이 되었음
  - 하지만 실제 이미지를 다룰 때는 Pixel로 표현을 함
  - Normalized 이미지 Plane 에서 Pixel Location으로 바꿔주는 정보가 필요함 (Intrisic Matrix K)

  

- Essential matrix with Intrinsic Matrix(K)

  - 1개의 카메라일 때는 K 값이 같음
  - 2개의 카메라일 때는 K 값이 다름
  - Essential Matrix를 조금 더 쉽게 쓰기 위해 E Matrix 자체에 K Matrix를 넣음
  - 왼쪽과 오른쪽에 K Matrix의 Inverse를 곱해줌
  - K Matrix의 정보도 함께 Epipolar Constraint에 넣으면 더 이상 Essential  Matrix라고 부르지 않고 **Fundamental** **Matrix**라고 부름

![image](https://github.com/shpark98/Projects/assets/116723552/8ea93770-ca64-4f7d-b0fe-102d2e8e3559)



#### Fundamental Matrix

- Fundamental에 x를 곱해주면 반대편의 line에 대한 식이 나타남
- line과 point가 교차하면 두 값의 dot product는 0
  - 이 방식을 이용해서 corresopondence를 굉장히 빠르게 찾을 수 있음
  - F Matrix를 이용해서 라인을 구하고, 구한 라인의 식과 dot product를 해서 0이 나오는 픽셀들만 사용하면 됨

![image](https://github.com/shpark98/Projects/assets/116723552/0e89df9a-9524-4f4f-aa9c-396a7e3699ca)

<img src="https://github.com/shpark98/Projects/assets/116723552/1320d46d-602f-4ca3-a4be-81a240b61af9" alt="image" style="zoom:67%;" />





Essential Matrix를 구할때는 5-Point Algorithm / Fundamental Matrix를 구할때는 8-Point Algorithm



- 최소 5개의 correspondence가 있어야 Essential Matrix를 구할  수 있고 최소 8개의 correspondence가 있어야 Fundamental Matrix를 구할 수 있음
- Fundamental Matrix 7 DoF (tx, ty, tz, rx, ry, rz, f, c 에서 scale 값을 구할 수 없어 8 -1 = 7 )
  - Non Minimal Solver
  - cv에서 findFundamentalMat() 함수를 사용
- Essential Matrix 5 DoF (tx, ty, tz, rx, ry, rz 에서 scale 값을 구할 수 없어 6 -1 = 5 )
  - Minimal Solver
  - cv에서 recoverPose() 함수를 사용

- correspondence는?
  - Feature Descriptor간의 Match 정보
    - 왼쪽 이미지에서 나타는 Feature가 오른쪽 이미지의 어떤 Feature과 맞는 것인가



##### Fundamental Matrix song

https://youtu.be/DgGV3l82NTk
