---
published: true

layout: single

title: "[2023-06-05] 자율주행 Perception 기술"

categories: [Devcourse-TIL]

tags: Autonomous_Driving CV

toc: true

toc_label : 목차

toc_sticky: true

author_profile: false

sidebar :
    nav : "docs"
---

## 자율주행 Perception 기술



### 자율주행이란?

- 운전자의 개입(조작) 없이 목적지 까지 차량(Vehicle) 스스로 움직이는 기술

![image](https://github.com/shpark98/Projects/assets/116723552/38538b59-fe65-488a-bf9a-860b17158dd5)



### 자율주행 개요 기술 구성 요소

- Perception : 자율주행 차량의 주행 환경에 대한 다양한 정보를 인지하는 기술
- Localization : 자율주행 차량의 현재 위치를 추정하는 기술
- Planning : 자율주행 차량의 주행 환경, 위치 정보를 바탕으로 주행하는데 필요한 요소 (경로, 판단, ... )를 생성 및 결정하는 기술
  - Path Planning
    - Local Path Planning(LPP) 
    - Global Path Planning(GPP)
  - Mission Planning
  - Decision Making
- Control : 자율주행 차량이 원할한 주행을 할 수 있도록 차량을 제어하는 기술

![image](https://github.com/shpark98/Projects/assets/116723552/b89d6c65-c59a-43df-8cd2-394d3ec7ace2)



#### Perception

- 자율주행 차량의 주행 환경 정보를 인지함
- 다양한 센서를 사용하여 주행에 필요한 정보를 인식
  - 인식된 다양한 정보로부터 자율주행 차량에 영향을 미칠 요소를 분석하고 측정하여 환경을 이해

<img src="https://github.com/shpark98/Projects/assets/116723552/32b89dce-dcd3-4eb1-9966-617dd580bb5d" alt="image" style="zoom: 67%;" />



#### Localization

- 자율주행 차량의 현재 위치를 파악
  - GNN 기반의 Global Position을 추정하는 방법 -> GPS / INS(& IMU) Fusion, GPS RTK, ...
  - 다른 센서 또는 데이터로(Perception 기술을 더해)부터 차량의 Global Position을 추정하는 방법 -> SLAM, Map Matching, ...

<img src="https://github.com/shpark98/Projects/assets/116723552/d889c2bb-9368-455a-aae0-af79330efd89" alt="image" style="zoom:67%;" />



#### Planning

- Path Planning : 경로 계획

  - Global Path Planning : 네비게이션처럼 현재 위치로부터 목적지까지 도로 단위의 경로를 결정하는 방법 

  - Local Path Planning : 현재 주행 환경에서 원할하고 안전한 주행을 위해 차선 단위의 경로를 결정하는 방법 (아래 그림 참조)

<img src="https://github.com/shpark98/Projects/assets/116723552/e4770269-0e69-4459-871d-88e28734637f" alt="image" style="zoom:67%;" />



#### Control

- 차량에 인가된 목표 값(Desired Value)을 만족하기 위한 차량의 요소를 제어하는 기술
  - 자동차의 경우 차량의 속도, 가속도, 순간 가속도, 스티어링을 제어함
- 제어 대상의 Dynamics을 분석하고 주행 환경과의 상호작용을 통해 차량의 안정성을 제어함

<img src="https://github.com/shpark98/Projects/assets/116723552/454335da-2e53-483c-be4a-4fd056009444" alt="image" style="zoom: 80%;" />



### 자율주행 시스템 아키텍처

<img src="https://github.com/shpark98/Projects/assets/116723552/98e5705a-a0c8-4535-88f6-057224df69cc" alt="image" style="zoom:80%;" />

![image](https://github.com/shpark98/Projects/assets/116723552/01d32217-ef94-4337-bee9-2bb32338570e)



### 자율주행 자동차의 2가지 갈래

<img src="https://github.com/shpark98/Projects/assets/116723552/ef294ffb-c9e1-436d-acad-867ba1297e07" alt="image" style="zoom:67%;" />



### HD Map vs Nevigation Map

- HD Map은 자율주행에 필요한 다양한 정보, 정확한 지도 데이터를 제공하는 장점이 있지만 지도 젲가과 유지보수가 어려운 단점이 있음

![ ](https://github.com/shpark98/Projects/assets/116723552/02218ad8-bbcd-403b-80dd-b0fa90380866)



### Perception 기술 분류

- 다양한 특징을 가지는 센서를 사용함
- 센서의 고유한 특징을 활용하여 종합적인 정보를 추정함
- 센서
  - Camera
  - LiDAR
  - RADAR
- 기술
  - Detection
  - Segmentation
  - Tracking
  - Prediction
  - 3D POSE Estimation
  - Sensor Fusion
  - Acceleration



### Detection 

- Vision, Lidar, Radar등 다양한 센서를 활용하여 주행 환경에 존재하는 특정 객체를 검출
- Vision 기반의 2D Image Object Detection / Lidar, Radar를 활용한 3D Point Cloud Object Detection이 있음
  - 최근에는 Vision 기반의 3D Object Detection을 검출하려는 다양한 노력이 있음

<img src="https://github.com/shpark98/Projects/assets/116723552/3f89f765-4038-4c7e-82cd-2f3028487461" alt="image" style="zoom: 67%;" />



### Segmentation

- Segmentation은 객체의 형태를 분할하는 기법으로 Bounding Box와는 출력 결과가 다름
- Vision, Point Cloud 등 다양한 센서를 활용함

<img src="https://github.com/shpark98/Projects/assets/116723552/ac6da675-6ef9-4d57-8bd9-4cf82294494d" alt="image" style="zoom: 80%;" />

- Drivable Area Detection

<img src="https://github.com/shpark98/Projects/assets/116723552/4d7b6544-be5a-4ebf-b1b2-81d220206101" alt="image" style="zoom:67%;" />



### Tracking

- 검출한 객체의 고유한 ID를 부여하고 해당 객체가 동일한 객체임을 추적하는 기술
- 객체의 움직임을 지속적으로 추적해서 객체의 미래의 움직임을 예측하는 기술
  - Multiple Object Tracking : 다중 객체 추적
  - Single Object Tracking : 단일 객체 추적

<img src="https://github.com/shpark98/Projects/assets/116723552/6f7aa9ea-c1de-45bb-9769-3bc1a5bc0de6" alt="image" style="zoom:67%;" />



### Prediction

- Tracking뿐만 아니라 주변 환경, 객체의 고유한 특징등 다양한 정보를 바탕으로 객체의 미래 움직임을 추정함
- Multimodal Trajectory Prediction이라는 키워드로 활발한 연구가 진행중

<img src="https://github.com/shpark98/Projects/assets/116723552/f276d020-e369-4805-aeb3-1170333e8c3c" alt="image" style="zoom:67%;" />



### 3D POSE Estimation

- 객체를 인식하는 것 뿐만 아니라, 객체의 정확한 위치를 추정하는 기술은 매우 중요함
- Vision의 Geometry 정보를 사용하는 방법과 위치 정보를 획득할 수 있는 다른 센서와의 데이터 융합 방법으로 구분

![image](https://github.com/shpark98/Projects/assets/116723552/b5910ecd-6e7d-4eab-95f8-62cead0b74cd)



### Sensor Fusion

- 유의미한 정보를 획득하기 위해 센서 데이터들을 융합
- 각 센서는 고유한 장/단점을 가지고 있음

- Camera vs Lidar

  - Lidar는 객체를 구분할 수 없지만, 위치 정보를 획득할  수 있음

  - Camera는 객체의 위치 정보를 획득할 수 없지만, 대상이 무엇인지 구별할 수 있음



<img src="https://github.com/shpark98/Projects/assets/116723552/e31ca7cf-810f-4ca0-9502-b1e86d490744" alt="image" style="zoom:67%;" />



### Acceleration

- Perception의 많은 알고리즘이 Deep Learning 기반으로 변화하면서 컴퓨팅 파워에 대한 수요가 급증하고 있음
- 자율주행은 빠른 속도로 움직이는 환경이기 때문에, 검출 성능 뿐만 아니라 검출 속도도 중요한 키워드
- Model Quantization, Pruning, Hardware Optimization등 다양한 최적화 방법이 존재함
