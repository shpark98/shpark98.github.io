---
published: true

layout: single

title: "[2023-06-28] 영상처리 기반 자이카 정지선 인식"

categories: [Devcourse-TIL]

tags: Autonomous_Driving CV

toc: true

toc_label : 목차

toc_sticky: true

author_profile: false

sidebar :
    nav : "docs"
---

## 영상처리 기반 정지선 인식



### 정지선을 감지하기 위해?

- 정지선 색 찾기
  - 흰색
  - 노란색
- 도로 위에 있는 너비가 큰 직사각형을 찾기
- 횡단보도가 있다면, 횡단보도와 정지선 구분



#### HSL

- 색조 밝기 채도 모델
- L 채널 : 밝기를 표시하여 흰색을 찾는데 유용하게 사용 -> 차선, 정지선을 찾는데 유용함



#### LAB

- 인간이 인지하는 밝기, 적록색, 황청색의 조합으로 표현
- 일반적으로 피부색을 찾는데 많이 사용 -> 노란색 차선을 찾는데 유용함



#### 흰색 감지

- white.py

```python
#!usr/bin/env python
# -*- coding: utf-8 -*-

import cv2
original = cv2.imread("white.png", cv2.IMREAD_UNCHANGED)

H, L, S = cv2.split(cv2.cvtColor(original, cv2.COLOR_BGR2HLS))

_, H = cv2.threshold(H, 125, 255, cv2.THRESH_BINARY)
_, L = cv2.threshold(L, 125, 255, cv2.THRESH_BINARY)
_, S = cv2.threshold(S, 125, 255, cv2.THRESH_BINARY)

cv2.imshow("original", original)
cv2.imshow("H", H)
cv2.imshow("L", L)
cv2.imshow("S", S)

cv2.waitKey(0)
cv2.destroyAllWindows()
```

- L 채널이 흰색의 선명도가 가장 좋음

<img width="824" alt="image" src="https://github.com/shpark98/Projects/assets/116723552/7d9768cd-56e7-47c1-b7c5-7ae04a12317c">



#### 노랑색 감지

- yellow.py

```
#!usr/bin/env python
# -*- coding: utf-8 -*-

import cv2

original = cv2.imread("yellow.png", cv2.IMREAD_UNCHANGED)


L, A, B = cv2.split(cv2.cvtColor(original, cv2.COLOR_BGR2LAB))

_, L = cv2.threshold(L, 156, 255, cv2.THRESH_BINARY)
_, A = cv2.threshold(A, 156, 255, cv2.THRESH_BINARY)
_, B = cv2.threshold(B, 156, 255, cv2.THRESH_BINARY)

cv2.imshow("original", original)
cv2.imshow("L", L)
cv2.imshow("A", A)
cv2.imshow("B", B)

cv2.waitKey(0)
cv2.destroyAllWindows()
```

- B 채널 황색의 선명도가 가장 좋음

<img width="792" alt="image" src="https://github.com/shpark98/Projects/assets/116723552/76b32ade-cc30-45db-866c-e78b4dbd7bcf">



### 카메라 캘리브레이션

- 이미지 처리 기능의 구현에는 일반화 작업이 중요
  - 카메라 캘리브레이션은 일반화 작업에서 매우 중요한 요소



#### 자이카 ROS Camera Calibration

1. 체크보드 A4 용지 준비 (https://cafe.naver.com/xytron/311)
2. `$ roslaunch usb_cam usb_cam-test.launch`자이카 리눅스 콘솔창에 usb_cam 노드를 실행
3. `$ rosrun camera_calibration cameracalibrator.py -size 8x6 -square ① image:=/usb_cam/image_raw camera:=/usb_cam ` 을 입력해 ROS Camera Calibration Program 실행
4. Camera Calibration Program에 우측 상단의 4가지 Bar가 녹색이 될 때 까지 체크보드 A4 용지를 움직임
5. ROS Camera Calibration 프로그램 캘리브레이션에 필요한 데이터를 최소한으로 충족하게 되면, 동그라미 버튼이 활성화됨
6. Calibrate 버튼을 누르면 지금까지 모은 데이터를 토대로 캘리브레이션 수치를 만듬
7. Save 버튼을 누르면 /tmp/calibrationdata.tar.gz 경로에 저장됨
8. 경로에 들어가 calibrationdata.tar.gz 파일의 압축을 풀고 저장되어있는 ost.yaml 파일 열기
9. camera_matrix와 distortion_coefficients를 확인

<img width="884" alt="image" src="https://github.com/shpark98/Projects/assets/116723552/bcab660c-6883-4aed-9e7a-cc3ccc639ade" style="zoom:80%;" >



### countNonZero 활용

- 횡단보도와 정지선의 차이	
