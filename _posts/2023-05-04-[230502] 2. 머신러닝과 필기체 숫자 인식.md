---
published: true

layout: single

title: "[2023-05-02] 2. 머신러닝과 필기체 숫자 인식"

categories: [Devcourse-TIL, CV]

tags: Autonomous_Driving CV OpenCV

toc: true

toc_label : 목차

toc_sticky: true

author_profile: false

sidebar :
    nav : "docs"
---

### 머신러닝

- 주어진 데이터를 분석하여 규칙성, 패턴 등을 찾고, 이를 이용하여 의미 있는 정보를 추출하는 과정

<img src="https://user-images.githubusercontent.com/116723552/236011280-0f1f2023-7b02-411b-aa05-629b7220d4be.png" alt="image" style="zoom:67%;" />



#### 머신러닝의 예

- 머신러닝에 의한 붓꽃 분류
  - 붓꽃(IRIS) 품종 분류 : Setosa vs Versicolor
  - 꽃잎(petal)과 꽃받침(sepal)의 길이에 의한 분류

![image](https://user-images.githubusercontent.com/116723552/236015077-611a645e-e8f6-43c6-9f27-30fe74937f9b.png)

- Adaline : Adaptive Linear Neruon

<img src="https://user-images.githubusercontent.com/116723552/236014965-f8dc18ea-593e-413d-98f2-14bdacf49452.png" alt="image" style="zoom: 50%;" />



#### 머신러닝의 종류

![image](https://user-images.githubusercontent.com/116723552/236015313-344dec0d-753f-4d11-be06-1a1f726e0291.png)



#### 머신러닝의 단계

- 훈련(Train) : 훈련 데이터를 이용하여 모델 을 학습하는 과정
- 예측(Predict) : 학습된 모델을 이용하여 새로운 데이터로부터 적절한 값을 예측하는 과정. 추론(Inference)

![image](https://user-images.githubusercontent.com/116723552/236016147-4624fef7-3746-4c80-8fa0-91918295179f.png)



#### 머신러닝학습의 목적

- 미래의 새로운 데이터를 더 정확하게 예측하기 위함
  - 모델의 일반화 성능을 향상시키는 방향으로 학습해야 함



![image](https://user-images.githubusercontent.com/116723552/236017376-c6912e4f-5516-43df-9f5c-bf478cd10ce9.png)



- 과적합(overfitting)

  - 훈련 데이터 셋을 지나치게 정확하게 구분하도록 학습하여 모델의 일반화 성능이 떨어지게 되는 현상

    - 훈련 데이터 셋이 너무 적은 경우에 발생함

    - 훈련 데이터 셋이 전체 데이터 셋의 특성/분포를 반영하지 않은 경우에도 발생함

  - 모델이 복잡할수록 과적합 발생확률이 높음



#### 훈련 데이터의 분할

- 학습 가능한 데이터를 훈련, 검증, 테스트 데이터 셋으로 분할하여 사용

![image](https://user-images.githubusercontent.com/116723552/236018110-d9590e71-bed8-482a-9ea9-c77d277fc2f9.png)



- K-폴드 교차 검증(k-fold cross-validation)
  - 훈련 데이터를 k개로 분할하여 여러 번 검증 수행

![image](https://user-images.githubusercontent.com/116723552/236018502-18885e87-4bb1-4b59-9ac4-f681e0fe7671.png)

#### OpenCV 머신러닝 클래스

![image](https://user-images.githubusercontent.com/116723552/236019260-a3d6f896-3ca2-4f41-bd1f-62bf43b9059b.png)



- 머신러닝 클래스 설명

<img src="https://user-images.githubusercontent.com/116723552/236019617-19d7895b-3752-4e48-8300-de182ec76ea2.png" alt="image" style="zoom: 80%;" />

<img src="https://user-images.githubusercontent.com/116723552/236019687-c627a119-0a2a-4da6-a434-077e446cb504.png" alt="image" style="zoom:80%;" />



##### 머신러닝 알고리즘 훈련

```
virtual bool StatModel::train(InputArray samples, int layout, InputArray responses);
```

- samples : 훈련 데이터 행렬
- layout : 훈련 데이터 배치 방법
  - ROW_SAMPLE : 하나의 데이터가 한 행으로 구성됨
  - COL_SAMPLE : 하나의 데이터가 한 열로 구성됨
- responses : 각 훈련 데이터에 대응되는 응답(레이블) 행렬
- 반환값 : 훈련이 잘 되었으면 true



##### 머신러닝 알고리즘 예측

```
virtual float StatModel::predict(InputArray samples, OutputArray results = noArray(), int flags = 0) const;
```

- samples : 입력 벡터가 행 단위로 저장된 행렬(CV_32F)
- results : 각 입력 샘플에 대한 예측(분류 or 회귀) 결과를 저장한 행렬
- flags : 추가적인 플래그 상수
- 반환값 : 입력 벡터가 하나인 경우에 대한 응답



#### 서포터 벡터 머신(SVM) 알고리즘

- 기본적으로 2개의 그룹(데이터)을 분리하는 방법으로 데이터들과 거리가 가장 먼 초평면(hyperplane)을 선택하여 분리하는 방법

![image](https://user-images.githubusercontent.com/116723552/236022593-e700328b-27bc-41ea-9135-8e530a82ea3e.png)

- 최대 마진 초평면 구하기

![image](https://user-images.githubusercontent.com/116723552/236023641-98211390-4cd9-452a-b9dc-a654f01374a3.png)



- 오분류 에러 허용하기
  - 주어진 샘플을 완벽하게 두 개의 그룹으로 선형 분리를 할 수 없을 경우, 오분류 에러를 허용(Soft margin, C-SVM)

![image](https://user-images.githubusercontent.com/116723552/236024356-e4fd4c71-19d1-40d4-b1b3-06e1e9e5246a.png)



- 비선형 데이터 분류하기
  - SVM은 선형 분류 알고리즘이지만 실제 데이터는 비선형으로 분포할 수 있음
  - 비선형 데이터의 차원을 확장하면 선형으로 분리가 가능함



<img src="https://user-images.githubusercontent.com/116723552/236025574-b7e7983c-2b74-4462-b1f8-d1beca10996d.png" alt="image" style="zoom:67%;" />



<img src="https://user-images.githubusercontent.com/116723552/236027521-f3dce654-0d77-4f90-8968-c07547654ff8.png" alt="image"  />





##### SVM 객체 생성

```
static Ptr<SVM> SVM::create();
```

- 비어있는 SVM 객체를 생성
- StatModel::train() 메소드를 이용하여 훈련을 해서 사용해야 함



##### SVM 타입 지정

```
Virtual void SVM::setType(int val)
```

- val : SVM::Types 열거형 상수 중 하나를 지정

![image](https://user-images.githubusercontent.com/116723552/236026574-8646765e-838f-48d1-af10-2f31d411bfc6.png)



##### SVM 커널 지정

```
Virtual void SVM::setKernel(int kernelType);
```

- kernelType : 커널 함수 종류. SVM::KernelTypes 열거형 상수 지정

![image](https://user-images.githubusercontent.com/116723552/236026931-8023b30e-fa9b-4444-9d95-2c0da422513a.png)



##### SVM 자동 훈련

![image](https://user-images.githubusercontent.com/116723552/236027124-3b12ded5-68d4-4dd6-9abc-1e651b14dc6e.png)

- K-폴드 교차 검증을 통해 최선의 파라미터를 찾아 훈련함



#### SVM을 이용한 2차원 점 분류 예제 코드

```
#include <iostream>
#include "opencv2/opencv.hpp"

using namespace std;
using namespace cv;
using namespace cv::ml;

int main()
{
	Mat train = Mat_<float>({ 8, 2 }, { 
		150, 200, 200, 250, 100, 250, 150, 300,
		350, 100, 400, 200, 400, 300, 350, 400 });
		// 첫번째 점의 x, y, 두번째 점의 x, y 순서로 총 8개 점의 좌표
		
	Mat label = Mat_<int>({ 8, 1 }, { 0, 0, 0, 0, 1, 1, 1, 1 });
	// 각각의 점들의 클래스 번호로 처음 4개의 점은 0번, 그 뒤에 4개의 점은 1번

	Ptr<SVM> svm = SVM::create(); // svm 객체 생성

#if 1
	svm->setType(SVM::C_SVC); // svm 객체 타입 설정
	svm->setKernel(SVM::RBF); // svm 객체 커널 설정
	svm->trainAuto(train, ROW_SAMPLE, label);
	// 자동으로 최적의 하이퍼파라미터를 찾아 모델을 학습하는 함수
#else
	svm->setType(SVM::C_SVC);
	svm->setKernel(SVM::LINEAR);
	svm->trainAuto(train, ROW_SAMPLE, label);
#endif

	cout << svm->getC() << endl;
	cout << svm->getGamma() << endl;

	Mat img = Mat::zeros(Size(500, 500), CV_8UC3); 500 x 500의 비어있는 영상을 만듬

	for (int y = 0; y < img.rows; y++) { // 각각의 픽셀값 좌표를
		for (int x = 0; x < img.cols; x++) {
			Mat test = Mat_<float>({ 1, 2 }, { (float)x, (float)y });
			int res = cvRound(svm->predict(test));

			if (res == 0)
				img.at<Vec3b>(y, x) = Vec3b(128, 128, 255); // R 빨강색으로 채우기
			else
				img.at<Vec3b>(y, x) = Vec3b(128, 255, 128); // G 녹색으로 채우기
		}
	}

	for (int i = 0; i < train.rows; i++) {
		int x = cvRound(train.at<float>(i, 0));
		int y = cvRound(train.at<float>(i, 1));
		int l = label.at<int>(i, 0);

		if (l == 0)
			circle(img, Point(x, y), 5, Scalar(0, 0, 128), -1, LINE_AA); // R
		else
			circle(img, Point(x, y), 5, Scalar(0, 128, 0), -1, LINE_AA); // G
	}

	imshow("svm", img);
	waitKey();
}
```

- 점들의 분포는 다음과 같음

<img src="https://user-images.githubusercontent.com/116723552/236028822-a4b53555-2f29-4224-b7e3-d4d28ba84fbf.png" alt="image" style="zoom: 80%;" />



- 결과

<img src="https://user-images.githubusercontent.com/116723552/236031847-4b0eb2f3-25c4-4b5f-b6d3-222ad39eb151.png" alt="image" style="zoom:80%;" />



- ​	svm->setKernel(SVM::LINEAR);

<img src="https://user-images.githubusercontent.com/116723552/236032636-fef04008-0d16-4796-8adf-0e3d4dfb46ea.png" alt="image" style="zoom:80%;" />



#### HOG 알고리즘

- Histogram of Oriented Gradients

- 영상의 지역적 그래디언트 방향 정보를 벡터로 사용
- 2005년 CVPR 학회에서 보행자 검출 방법으로 소개되어 널리 사용되기 시작함
- 이후 다양한 객체 인식에서 활용됨



#### HOG & SVM 필기체 숫자 인식
